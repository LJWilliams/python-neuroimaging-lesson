{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tractography \n",
    "\n",
    "Tractography requires the following elements: \n",
    "\n",
    "- ODF peaks in each voxel based on a reconstruction model.\n",
    "- A tissue classification criterion (we want to track only in the white matter!).\n",
    "- Tracking seeds (where to start tracking).\n",
    "- A direction getter - a rule for getting directions. \n",
    "\n",
    "That last one determines, for example, whether we are doing determinstic or probabilistic tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by getting some data. This time, we're also getting some Freesurfer labels associated with this \n",
    "data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is already in place. If you want to fetch it again please first remove the folder /Users/arokem/.dipy/stanford_hardi \n",
      "Dataset is already in place. If you want to fetch it again please first remove the folder /Users/arokem/.dipy/stanford_hardi \n",
      "Dataset is already in place. If you want to fetch it again please first remove the folder /Users/arokem/.dipy/stanford_hardi \n"
     ]
    }
   ],
   "source": [
    "from dipy.data import read_stanford_labels\n",
    "\n",
    "hardi_img, gtab, labels_img = read_stanford_labels()\n",
    "data = hardi_img.get_data()\n",
    "labels = labels_img.get_data()\n",
    "affine = hardi_img.get_affine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The white matter is labels '1' and '2' in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "white_matter = (labels == 1) | (labels == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the CSD model as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dipy.reconst.csdeconv import auto_response\n",
    "response, ratio = auto_response(gtab, data, roi_radius=10, fa_thr=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dipy.reconst.csdeconv import ConstrainedSphericalDeconvModel\n",
    "csd_model = ConstrainedSphericalDeconvModel(gtab, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dipy.direction import peaks_from_model\n",
    "from dipy.data import default_sphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peaks from model. \n",
    "\n",
    "The tracking will require a peak crea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csd_peaks = peaks_from_model(csd_model, data, default_sphere,\n",
    "                             relative_peak_threshold=.8,\n",
    "                             min_separation_angle=45,\n",
    "                             mask=white_matter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things interesting (and also because it's considered best practice), we'll use the generalized fractional anistropy (GFA) calculated from another reconst model (CSA) to determine our tissue classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dipy.reconst.shm import CsaOdfModel\n",
    "csa_model = CsaOdfModel(gtab, sh_order=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csa_fit = csa_model.fit(data, mask=white_matter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GFA = csa_fit.gfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dipy.tracking.local import ThresholdTissueClassifier\n",
    "classifier = ThresholdTissueClassifier(GFA, .25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seed in the corpus callosum (label '2' in the Freesurfer labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dipy.tracking import utils\n",
    "\n",
    "seed_mask = labels == 2\n",
    "seeds = utils.seeds_from_mask(seed_mask, density=[2, 2, 2], affine=affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to put it all together, with the LocalTracking tracker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dipy.tracking.local import LocalTracking\n",
    "streamlines = LocalTracking(csd_peaks, classifier, seeds, affine, step_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dipy.tracking.local.localtracking.LocalTracking"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(streamlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object is a Python 'generator' object. That means that computation is deferred until it is actually needed. This is useful in some situations where filtering of a massive number of streamlines is done, and you don't want to store them all in memory at once.\n",
    "\n",
    "In this case, we can generate all the streamlines at once, by turning the generator into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "streamlines = list(streamlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: what are the units and coordinate frame of the streamlines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arokem/source/dipy/dipy/viz/colormap.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  orient = np.abs(orient / np.linalg.norm(orient))\n"
     ]
    }
   ],
   "source": [
    "from dipy.viz import fvtk\n",
    "from dipy.viz.colormap import line_colors\n",
    "\n",
    "# Prepare the display objects.\n",
    "color = line_colors(streamlines)\n",
    "streamlines_actor = fvtk.line(streamlines, line_colors(streamlines))\n",
    "\n",
    "# Create the 3d display.\n",
    "ren = fvtk.ren()\n",
    "fvtk.add(ren, streamlines_actor)\n",
    "\n",
    "# Save still images for this static example. Or for interactivity use fvtk.show\n",
    "fvtk.record(ren, n_frames=1, out_path='deterministic.png',\n",
    "            size=(800, 800))\n",
    "fvtk.show(ren)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving tracks to file: \n",
    "\n",
    "We can save the tracks directly to the standard `trk` file format: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dipy.io.trackvis import save_trk\n",
    "save_trk(\"CSD_detr.trk\", streamlines, affine, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic tracking\n",
    "\n",
    "The difference between deterministic tracking and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csd_fit = csd_model.fit(data, mask=white_matter)\n",
    "shm_coeff = csd_fit.shm_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dipy.direction import ProbabilisticDirectionGetter\n",
    "\n",
    "prob_dg = ProbabilisticDirectionGetter.from_shcoeff(shm_coeff,\n",
    "                                                    max_angle=30.,\n",
    "                                                    sphere=default_sphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "streamlines = LocalTracking(prob_dg, classifier, seeds, affine,\n",
    "                            step_size=.5, max_cross=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute streamlines and store as a list.\n",
    "streamlines = list(streamlines)\n",
    "\n",
    "# Prepare the display objects.\n",
    "color = line_colors(streamlines)\n",
    "streamlines_actor = fvtk.line(streamlines, line_colors(streamlines))\n",
    "\n",
    "# Create the 3d display.\n",
    "ren = fvtk.ren()\n",
    "fvtk.add(ren, streamlines_actor)\n",
    "\n",
    "# Save still images for this static example.\n",
    "fvtk.record(ren, n_frames=1, out_path='probabilistic.png',\n",
    "            size=(800, 800))\n",
    "\n",
    "fvtk.show(ren)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Can you track using the DTI model? Could you compare deterministic and probabilistic tracking with DTI?\n",
    "\n",
    "A `peaks_from_model` object has a `shm_coeff` attribute that can be used to create a ProbabilisticDirectionGetter object using the `from_shcoeff` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
